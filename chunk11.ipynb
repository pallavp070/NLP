{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO26SnGhqg5E5tZrblol9zW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xkCnva9TcCci","executionInfo":{"status":"ok","timestamp":1746465833327,"user_tz":-330,"elapsed":17,"user":{"displayName":"PALLAV PRABHASH","userId":"13519120397589374682"}},"outputId":"5a2a77e3-17a9-4bc9-d231-98d3763552ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Chunked Sentence (Textual Representation):\n","(S\n","  (NP The/DT quick/JJ brown/NN)\n","  (NP fox/NN)\n","  (VP jumped/VBD)\n","  (PP over/IN (NP the/DT lazy/JJ dog/NN))\n","  ./.)\n","Error in drawing tree: no display name and no $DISPLAY environment variable\n","Please use .pprint() for text-based visualization instead.\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n"]}],"source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk import pos_tag, RegexpParser\n","\n","# Download necessary NLTK data\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger_eng')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('words')\n","\n","# Example sentence\n","sentence = \"The quick brown fox jumped over the lazy dog.\"\n","\n","# Step 1: Tokenize the sentence\n","tokens = word_tokenize(sentence)\n","\n","# Step 2: Part-of-speech tagging\n","tags = pos_tag(tokens)\n","\n","# Step 3: Define chunk grammar using regular expressions\n","chunk_grammar = r\"\"\"\n","  NP: {<DT>?<JJ>*<NN>}        # Noun Phrase\n","  VP: {<VB.*>}                 # Verb Phrase\n","  PP: {<IN><NP>}               # Prepositional Phrase\n","\"\"\"\n","\n","# Step 4: Create the chunk parser\n","chunk_parser = RegexpParser(chunk_grammar)\n","\n","# Step 5: Parse the sentence to get chunks\n","chunked_sentence = chunk_parser.parse(tags)\n","\n","# Step 6: Display the chunked sentence in text format\n","print(\"Chunked Sentence (Textual Representation):\")\n","chunked_sentence.pprint()\n","\n","# Step 7: Visualization (for environments that support it)\n","# Use .draw() method to display the tree in a graphical format\n","try:\n","    chunked_sentence.draw()  # This will open a graphical window if GUI is available\n","except Exception as e:\n","    print(f\"Error in drawing tree: {e}\")\n","    print(\"Please use .pprint() for text-based visualization instead.\")\n"]}]}