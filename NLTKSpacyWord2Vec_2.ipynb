{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# ---------- INSTALLATION ----------\n","# Install required NLP libraries\n","!pip install nltk spacy gensim --quiet\n","\n","# ---------- IMPORTS ----------\n","import nltk\n","import spacy\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer\n","from gensim.models import Word2Vec\n","\n","# ---------- DOWNLOAD NLTK RESOURCES ----------\n","nltk.download('punkt')  # Tokenizer data\n","nltk.download('stopwords')  # English stopword list\n","nltk.download('averaged_perceptron_tagger')  # POS tagger\n","nltk.download('punkt_tab')  # Optional tokenizer table (can be skipped safely)\n","\n","# ---------- SAMPLE TEXT ----------\n","text = \"Apple is looking at buying a U.K. startup for $1 billion\"\n","\n","# -------------------- 1️⃣ NLTK SECTION --------------------\n","print(\"\\n====== NLTK Basic Functions ======\")\n","\n","# Tokenization: Splits sentence into words\n","tokens = word_tokenize(text)\n","print(\"\\n1. Tokenized words:\", tokens)\n","\n","# Stopword Removal: Removes common words like 'is', 'at', etc.\n","stop_words = set(stopwords.words('english'))\n","filtered_tokens = [w for w in tokens if w.lower() not in stop_words]\n","print(\"\\n2. After Stop Word Removal:\", filtered_tokens)\n","\n","# Stemming: Reduces words to their root forms (e.g., 'buying' → 'buy')\n","stemmer = PorterStemmer()\n","stemmed = [stemmer.stem(w) for w in filtered_tokens]\n","print(\"\\n3. After Stemming:\", stemmed)\n","\n","# POS Tagging: Identifies parts of speech for each word\n","pos_tags = nltk.pos_tag(tokens)\n","print(\"\\n4. POS Tags:\", pos_tags)\n","\n","# -------------------- 2️⃣ spaCy SECTION --------------------\n","print(\"\\n====== spaCy Basic Functions ======\")\n","\n","# Load English NLP model (downloads if not already available)\n","try:\n","    nlp = spacy.load(\"en_core_web_sm\")\n","except OSError:\n","    spacy.cli.download(\"en_core_web_sm\")\n","    nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Process the text using spaCy\n","doc = nlp(text)\n","\n","# Tokenization & Lemmatization: Shows root form of each token\n","print(\"\\n1. Tokens and Lemmas:\")\n","for token in doc:\n","    print(f\"{token.text} → {token.lemma_}\")\n","\n","# POS Tagging: Grammatical role of each word\n","print(\"\\n2. POS Tags:\")\n","for token in doc:\n","    print(f\"{token.text} ({token.pos_})\")\n","\n","# Named Entity Recognition (NER): Detects named entities like companies, money, etc.\n","print(\"\\n3. Named Entities:\")\n","for ent in doc.ents:\n","    print(f\"{ent.text} ({ent.label_})\")\n","\n","# -------------------- 3️⃣ WORD2VEC SECTION --------------------\n","print(\"\\n====== Word2Vec Basic Example ======\")\n","\n","# Example corpus for training Word2Vec (each list = one sentence)\n","sentences = [\n","    ['cat', 'sits', 'on', 'the', 'mat'],\n","    ['dog', 'plays', 'with', 'ball'],\n","    ['man', 'reads', 'a', 'book'],\n","    ['book', 'contains', 'knowledge']\n","]\n","\n","# Train Word2Vec model\n","# vector_size = number of dimensions\n","# window = context window size\n","# sg = 1 uses skip-gram; sg = 0 uses CBOW\n","model = Word2Vec(sentences, vector_size=50, window=2, min_count=1, sg=1)\n","\n","# Get vector representation of word 'book'\n","print(\"\\n1. Vector for 'book':\")\n","print(model.wv['book'])\n","\n","# Find most similar words to 'book'\n","print(\"\\n2. Words similar to 'book':\")\n","print(model.wv.most_similar('book'))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HaP6_es36te4","executionInfo":{"status":"ok","timestamp":1746456729592,"user_tz":-330,"elapsed":3658,"user":{"displayName":"PALLAV PRABHASH","userId":"13519120397589374682"}},"outputId":"18e55419-f4ce-44e1-b45c-db5781c3d8ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["\n","====== NLTK Basic Functions ======\n","\n","1. Tokenized words: ['Apple', 'is', 'looking', 'at', 'buying', 'a', 'U.K.', 'startup', 'for', '$', '1', 'billion']\n","\n","2. After Stop Word Removal: ['Apple', 'looking', 'buying', 'U.K.', 'startup', '$', '1', 'billion']\n","\n","3. After Stemming: ['appl', 'look', 'buy', 'u.k.', 'startup', '$', '1', 'billion']\n","\n","4. POS Tags: [('Apple', 'NNP'), ('is', 'VBZ'), ('looking', 'VBG'), ('at', 'IN'), ('buying', 'VBG'), ('a', 'DT'), ('U.K.', 'NNP'), ('startup', 'NN'), ('for', 'IN'), ('$', '$'), ('1', 'CD'), ('billion', 'CD')]\n","\n","====== spaCy Basic Functions ======\n","\n","1. Tokens and Lemmas:\n","Apple → Apple\n","is → be\n","looking → look\n","at → at\n","buying → buy\n","a → a\n","U.K. → U.K.\n","startup → startup\n","for → for\n","$ → $\n","1 → 1\n","billion → billion\n","\n","2. POS Tags:\n","Apple (PROPN)\n","is (AUX)\n","looking (VERB)\n","at (ADP)\n","buying (VERB)\n","a (DET)\n","U.K. (PROPN)\n","startup (NOUN)\n","for (ADP)\n","$ (SYM)\n","1 (NUM)\n","billion (NUM)\n","\n","3. Named Entities:\n","Apple (ORG)\n","U.K. (GPE)\n","$1 billion (MONEY)\n","\n","====== Word2Vec Basic Example ======\n","\n","1. Vector for 'book':\n","[-1.0724545e-03  4.7286271e-04  1.0206699e-02  1.8018546e-02\n"," -1.8605899e-02 -1.4233618e-02  1.2917745e-02  1.7945977e-02\n"," -1.0030856e-02 -7.5267432e-03  1.4761009e-02 -3.0669428e-03\n"," -9.0732267e-03  1.3108104e-02 -9.7203208e-03 -3.6320353e-03\n","  5.7531595e-03  1.9837476e-03 -1.6570430e-02 -1.8897636e-02\n","  1.4623532e-02  1.0140524e-02  1.3515387e-02  1.5257311e-03\n","  1.2701781e-02 -6.8107317e-03 -1.8928028e-03  1.1537147e-02\n"," -1.5043275e-02 -7.8722071e-03 -1.5023164e-02 -1.8600845e-03\n","  1.9076237e-02 -1.4638334e-02 -4.6675373e-03 -3.8754821e-03\n","  1.6154874e-02 -1.1861792e-02  9.0324880e-05 -9.5074680e-03\n"," -1.9207101e-02  1.0014586e-02 -1.7519170e-02 -8.7836506e-03\n"," -7.0199967e-05 -5.9236289e-04 -1.5322480e-02  1.9229487e-02\n","  9.9641159e-03  1.8466286e-02]\n","\n","2. Words similar to 'book':\n","[('cat', 0.2105710357427597), ('the', 0.16704076528549194), ('sits', 0.15019884705543518), ('with', 0.13204392790794373), ('contains', 0.1267007291316986), ('dog', 0.0998455360531807), ('knowledge', 0.042373016476631165), ('on', 0.04067763686180115), ('man', 0.012442179024219513), ('mat', -0.01259106956422329)]\n"]}]}]}